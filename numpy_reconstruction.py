# -*- coding: utf-8 -*-
"""Recombining_wind.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1opNGNsNTX3nvlJZTfr7GtNzY65TTEbaj
"""

#pip install netCDF4
import netCDF4
import gzip
import shutil

# Commented out IPython magic to ensure Python compatibility.
import os
#from google.colab import drive
#drive.mount('/content/gdrive')
# %cd /content/gdrive/MyDrive/LiDAR/
from datetime import datetime
import numpy as np
import natsort
import pandas as pd

import re, seaborn as sns
import numpy as np
import pickle

from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.colors import ListedColormap
from scipy.spatial import KDTree

"""Combining the wind speeds according to distance, time and confidence."""

def complete_point_cloud(scan_data):

  sweep_data = natsort.natsorted([k for k in scan_data.groups.keys() if 'Sweep' in k])
  num_sweeps = len(sweep_data)

  sweep_angles = scan_data.variables['sweep_fixed_angle'][:].data

  if num_sweeps != len(sweep_angles):
    print('Number of sweeps does not match number of sweep angles')

  point_cloud_array = []

  for n in range(num_sweeps):

      try:
        cnr = scan_data.groups[sweep_data[n]].variables['cnr'][:].data # 120 - azimuthal angles and 35 distances (400 - 14400m at 400m resolution)
        cnr = np.nan_to_num(cnr, nan = -100)
      except:
        cnr = None
      if cnr is not None:
        azimuth = scan_data.groups[sweep_data[n]].variables['azimuth'][:].data
        time_val = scan_data.groups[sweep_data[n]].variables['time'][:].data
        timestamp = scan_data.groups[sweep_data[n]].variables['timestamp'][:]
        elevation = scan_data.groups[sweep_data[n]].variables['elevation'][:].data
        range_vals = scan_data.groups[sweep_data[n]].variables['range'][:].data
        theta_e = np.round(np.median(elevation))

        wind_speed = scan_data.groups[sweep_data[n]].variables['radial_wind_speed'][:].data
        wind_ci = scan_data.groups[sweep_data[n]].variables['radial_wind_speed_ci'][:].data

        xyz_list = []
        cnr_list = []
        timelist = []
        timestamp_list = []
        azimuth_list = []
        range_list = []

        wind_xyz_list = []
        wind_conf = []

        for i in range(len(azimuth)):
          for j in range(len(range_vals)):

            az = np.round(azimuth[i])
            rng = range_vals[j]

            Y = np.sin(az*(np.pi)/180) * rng * np.cos(theta_e*(np.pi)/180)
            X = np.cos(az*(np.pi)/180) * rng * np.cos(theta_e*(np.pi)/180)
            Z = rng * np.sin(theta_e*(np.pi)/180)

            xyz_list.append([X,Y,Z])
            cnr_list.append(cnr[i,j])

            windx = np.sin(az*(np.pi)/180) * wind_speed[i,j] * np.cos(theta_e*(np.pi)/180)
            windy = np.cos(az*(np.pi)/180) * wind_speed[i,j] * np.cos(theta_e*(np.pi)/180)
            windz = wind_speed[i,j] * np.sin(theta_e*(np.pi)/180)

            wind_xyz_list.append([windx, windy, windz])
            wind_conf.append(wind_ci[i,j])

            timelist.append(time_val[i])
            timestamp_list.append(timestamp[i])
            azimuth_list.append(az)
            range_list.append(rng)

        xyz_list = np.asarray(xyz_list).astype(float)
        windxyz_list = np.asarray(wind_xyz_list).astype(float)
        wind_conf = np.asarray(wind_conf).astype(float)

        cnr_list = np.asarray(cnr_list).astype(float)
        azimuth_list = np.asarray(azimuth_list).astype(float)
        range_list = np.asarray(range_list).astype(float)
        timelist = np.asarray(timelist).astype(float)
        sweep_id = np.zeros_like(cnr_list).astype(int) + n
        elevation_info = np.ones_like(cnr_list).astype(int) * theta_e

        tstamp_list = [datetime.strptime(timestamp_list[t][:-5],'%Y-%m-%dT%H:%M:%S') for t in range(len(timestamp_list))]
        tstamp_list = np.asarray(tstamp_list)


        wind_data = np.concatenate((windxyz_list, wind_conf.reshape(-1,1)), axis = 1)
        sweep_arr = np.concatenate((np.column_stack((sweep_id, timelist, tstamp_list,azimuth_list, range_list, elevation_info, cnr_list)), xyz_list, wind_data), axis = 1)
        #print(sweep_arr.shape, len(azimuth_list)*len(range_list))
        assert sweep_arr.shape[0] == len(azimuth_list)#*len(range_list)

        point_cloud_array.append(sweep_arr)

  if len(point_cloud_array) > 0:
      point_cloud_array = np.concatenate(point_cloud_array, axis = 0)

      point_cloud_df = pd.DataFrame(data=point_cloud_array,
                                index=np.arange(len(point_cloud_array)),
                                columns=['sweep_id',
                                         'time(s)',
                                         'timestamp',
                                         'azimuth(deg)',
                                         'radial_distance(m)',
                                         'elevation(deg)',
                                         'cnr',
                                         'X(m)',
                                         'Y(m)',
                                         'Z(m)',
                                         'wind_vel_X(m/s)',
                                         'wind_vel_Y(m/s)',
                                         'wind_vel_Z(m/s)',
                                         'wind_vel_confidence(%)'])


      # creating an ExcelWriter object

      # writing to the 'Employee' sheet
      #point_cloud_df.to_excel(writer, sheet_name = hour, index=False)
  else:
    point_cloud_df = None

  return point_cloud_array, point_cloud_df

def calc_tprob(tref, tnbrs):
  tdiff = np.abs(tnbrs - tref)
  td_exp = np.exp(-tdiff)
  tprob = td_exp / np.sum(td_exp)
  return tprob

def calc_dprob(dnbrs):
  dexp = np.exp(-(dnbrs**2))
  dprob = dexp / np.sum(dexp)
  return dprob

def avg_wspeed(wspeeds, wconfs, dnbrs, tnbrs, tref):

  # wspeeds.shape = num_nbr * 3
  # wconfs.shape = num_nbr * 1
  # dnbrs.shape = num_nbr * 1
  # tnbrs.shape = num_nbr * 1
  # tref.shape = 1

  wspeeds_final = np.sum(wspeeds * wconfs * calc_tprob(tref, tnbrs) * calc_dprob(dnbrs), axis = 0)

  return wspeeds_final

root_dir = './scans/'
dates = natsort.natsorted(os.listdir(root_dir))
#pcdir = './pcloud_norm/test/'
pcdir = root_dir
save_dir = './diff_clouds/'
#normalization_factors = np.load('./max_norm_coords_wind.npy')
max_coords = 14500 #normalization_factors[0]
max_wind = 10 #normalization_factors[1]
print(np.max(max_coords), np.max(max_wind))

if os.path.exists(pcdir) == False:
  os.mkdir(pcdir)

num_nbrs = 26

print("Dates is " + str(dates))

##volume


for d in dates:
    print(d)
    hours = natsort.natsorted(os.listdir(root_dir + '/' + d))

    for h in hours:

        print(h)
        minutes = natsort.natsorted(os.listdir(root_dir + '/' + d + '/' + h))
        for m in minutes:
          path = root_dir + d + '/' + h + '/' + m
          #filepath = root_dir + h
          filepath = path[:-3]
          print(path)
          print(filepath)
          
          try:
            with gzip.open(path, 'rb') as f_in:
                with open(filepath, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            #print(f"Successfully extracted '{path}' to '{filepath}'")
          except FileNotFoundError:
            print(f"Error: The file '{path}' was not found.")
          except Exception as e:
            print(f"An error occurred during extraction: {e}")
            
          print(filepath)

          if os.path.exists(filepath):
            scan_data = netCDF4.Dataset(filepath,'r')
            point_cloud_array, pcloud_df = complete_point_cloud(scan_data)

            if pcloud_df is not None:

              pc_data = pcloud_df
              coords = pc_data[['X(m)', 'Y(m)', 'Z(m)']].values.astype(float)
              print(coords.shape)
              wind_vels = pc_data[['wind_vel_X(m/s)', 'wind_vel_Y(m/s)', 'wind_vel_Z(m/s)']].values.astype(float)
              wind_confs = pc_data[['wind_vel_confidence(%)']].values.astype(float)
              time = pc_data[['time(s)']].values.astype(float)
              cnr = pc_data[['cnr']].values.astype(float)

              # Remove nans from CNR
              if np.any(np.isnan(cnr)):
                mask = np.isnan(cnr)
                cnr[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cnr[~mask])

              # Remove samples that have nans in coordinates
              if np.any(np.isnan(coords)):
                print("Nans")
                continue

              tree = KDTree(coords)
              feats = np.empty((coords.shape[0], 4))
              print(coords.shape)

              for cid in range(coords.shape[0]):

                dd, ii = tree.query(coords[cid:cid+1], k = num_nbrs)
                tnbrs = time[ii[0,:]]
                nbr_coords = coords[ii[0,:]]
                nbr_wind_vels = wind_vels[ii[0,:]]
                nbr_wind_confs = wind_confs[ii[0,:]]/100

                # Removing nans from wind vels
                nan_nbr_winds = np.nan_to_num(nbr_wind_vels, nan = 0)
                nan_nbr_confs = np.nan_to_num(nbr_wind_confs, nan = 0)
                wfinal = avg_wspeed(nbr_wind_vels, nbr_wind_confs, dd.T, tnbrs, time[cid])

                feats[cid, 0] = cnr[cid]
                feats[cid, 1:] = np.nan_to_num(wfinal, nan = 0)

              assert np.isnan(coords).any() == False
              assert np.isnan(feats).any() == False
              assert np.isnan(time).any() == False

              coords = coords/np.max(max_coords)
              feats[:,1:] = feats[:,1:]/np.max(max_wind)
              # Normalize data using wind and coordinate normalizations:

              pc_data_final = np.concatenate((coords, feats, time.reshape(-1,1)), axis = -1)

              print('Num point clouds: ', len(pc_data_final),
                    'Normalized Coords', np.max(np.linalg.norm(coords,axis=1)),
                    'Normalized Wind Max Norm: ', np.max(np.linalg.norm(feats[:,1:],axis=1)),
                    'Max_cnr: ', cnr.max(),
                    'Min_cnr: ', cnr.min(),
                    'Mean_cnr: ', cnr.mean())

              #Check if hour is one or two digits
              if int(h[:-3]) > 9:
                np.save( os.path.join(save_dir, d + '_' + h[:-3] + '_' + filepath[49:51] + '.npy'), pc_data_final)
              else:
                np.save( os.path.join(save_dir, d + '_' + h[:-3] + '_' + filepath[48:50] + '.npy'), pc_data_final)             
              
              print("Look below")
              print(filepath)
              print(filepath[49:51])
              print(filepath[48:50])

          else:
            print("plcoud_df was none")
        #else:
            #print("os path does not exist")
# save

'''Old code
for d in dates:
    print(d)
    hours = natsort.natsorted(os.listdir(root_dir + '/' + d))

    for h in hours:

        print(h)
        #filepath = root_dir + d + '/' + h + '/volume_scan.nc'
        filepath = root_dir + h
        print(filepath)

        if os.path.exists(filepath):
          scan_data = netCDF4.Dataset(filepath,'r')
          point_cloud_array, pcloud_df = complete_point_cloud(scan_data)

          if pcloud_df is not None:

            pc_data = pcloud_df
            coords = pc_data[['X(m)', 'Y(m)', 'Z(m)']].values.astype(float)
            print(coords.shape)
            wind_vels = pc_data[['wind_vel_X(m/s)', 'wind_vel_Y(m/s)', 'wind_vel_Z(m/s)']].values.astype(float)
            wind_confs = pc_data[['wind_vel_confidence(%)']].values.astype(float)
            time = pc_data[['time(s)']].values.astype(float)
            cnr = pc_data[['cnr']].values.astype(float)

            # Remove nans from CNR
            if np.any(np.isnan(cnr)):
              mask = np.isnan(cnr)
              cnr[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), cnr[~mask])

            # Remove samples that have nans in coordinates
            if np.any(np.isnan(coords)):
              print("Nans")
              continue

            tree = KDTree(coords)
            feats = np.empty((coords.shape[0], 4))
            print(coords.shape)

            for cid in range(coords.shape[0]):

              dd, ii = tree.query(coords[cid:cid+1], k = num_nbrs)
              tnbrs = time[ii[0,:]]
              nbr_coords = coords[ii[0,:]]
              nbr_wind_vels = wind_vels[ii[0,:]]
              nbr_wind_confs = wind_confs[ii[0,:]]/100

              # Removing nans from wind vels
              nan_nbr_winds = np.nan_to_num(nbr_wind_vels, nan = 0)
              nan_nbr_confs = np.nan_to_num(nbr_wind_confs, nan = 0)
              wfinal = avg_wspeed(nbr_wind_vels, nbr_wind_confs, dd.T, tnbrs, time[cid])

              feats[cid, 0] = cnr[cid]
              feats[cid, 1:] = np.nan_to_num(wfinal, nan = 0)

            assert np.isnan(coords).any() == False
            assert np.isnan(feats).any() == False
            assert np.isnan(time).any() == False

            coords = coords/np.max(max_coords)
            feats[:,1:] = feats[:,1:]/np.max(max_wind)
            # Normalize data using wind and coordinate normalizations:

            pc_data_final = np.concatenate((coords, feats, time.reshape(-1,1)), axis = -1)

            print('Num point clouds: ', len(pc_data_final),
                  'Normalized Coords', np.max(np.linalg.norm(coords,axis=1)),
                  'Normalized Wind Max Norm: ', np.max(np.linalg.norm(feats[:,1:],axis=1)),
                  'Max_cnr: ', cnr.max(),
                  'Min_cnr: ', cnr.min(),
                  'Mean_cnr: ', cnr.mean())


            np.save( os.path.join(save_dir, d + '_' + h[:-3] + '.npy'), pc_data_final)

          else:
            print("plcoud_df was none")
        else:
            print("os path does not exist")
    break'''
# save